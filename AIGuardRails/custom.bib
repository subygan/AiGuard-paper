@article{10.1145/3571730,
author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
title = {Survey of Hallucination in Natural Language Generation},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3571730},
doi = {10.1145/3571730},
abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
journal = {ACM Comput. Surv.},
month = {mar},
articleno = {248},
numpages = {38},
keywords = {Hallucination, intrinsic hallucination, extrinsic hallucination, faithfulness in NLG, factuality in NLG, consistency in NLG}
}

@misc{min2022rethinking,
      title={Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?}, 
      author={Sewon Min and Xinxi Lyu and Ari Holtzman and Mikel Artetxe and Mike Lewis and Hannaneh Hajishirzi and Luke Zettlemoyer},
      year={2022},
      eprint={2202.12837},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{peng2023instruction,
      title={Instruction Tuning with GPT-4}, 
      author={Baolin Peng and Chunyuan Li and Pengcheng He and Michel Galley and Jianfeng Gao},
      year={2023},
      eprint={2304.03277},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2024stablept,
      title={StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation}, 
      author={Xiaoming Liu and Chen Liu and Zhaohan Zhang and Chengzhengxu Li and Longtian Wang and Yu Lan and Chao Shen},
      year={2024},
      eprint={2404.19335},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{NEURIPS2023_8678da90,
 author = {Ma, Huan and Zhang, Changqing and Bian, Yatao and Liu, Lemao and Zhang, Zhirui and Zhao, Peilin and Zhang, Shu and Fu, Huazhu and Hu, Qinghua and Wu, Bingzhe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {43136--43155},
 publisher = {Curran Associates, Inc.},
 title = {Fairness-guided Few-shot Prompting for Large Language Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/8678da90126aa58326b2fc0254b33a8c-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@article{dwivedi2023breaking,
  title={Breaking the Bias: Gender Fairness in LLMs Using Prompt Engineering and In-Context Learning},
  author={Dwivedi, Satyam and Ghosh, Sanjukta and Dwivedi, Shivam},
  journal={Rupkatha Journal on Interdisciplinary Studies in Humanities},
  volume={15},
  number={4},
  year={2023}
}

@article{schubert2024context,
  title={In-context learning agents are asymmetric belief updaters},
  author={Schubert, Johannes A and Jagadish, Akshay K and Binz, Marcel and Schulz, Eric},
  journal={arXiv preprint arXiv:2402.03969},
  year={2024}
}


@article{asai2024reliable,
  title={Reliable, adaptable, and attributable language models with retrieval},
  author={Asai, Akari and Zhong, Zexuan and Chen, Danqi and Koh, Pang Wei and Zettlemoyer, Luke and Hajishirzi, Hannaneh and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2403.03187},
  year={2024}
}

@article{yan2024corrective,
  title={Corrective Retrieval Augmented Generation},
  author={Yan, Shi-Qi and Gu, Jia-Chen and Zhu, Yun and Ling, Zhen-Hua},
  journal={arXiv preprint arXiv:2401.15884},
  year={2024}
}
@misc{lewis2021retrievalaugmented,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@incollection{gormley2019mixture,
  title={Mixture of experts models},
  author={Gormley, Isobel Claire and Fr{\"u}hwirth-Schnatter, Sylvia},
  booktitle={Handbook of mixture analysis},
  pages={271--307},
  year={2019},
  publisher={Chapman and Hall/CRC}
}

@article{xu2024hallucination,
  title={Hallucination is inevitable: An innate limitation of large language models},
  author={Xu, Ziwei and Jain, Sanjay and Kankanhalli, Mohan},
  journal={arXiv preprint arXiv:2401.11817},
  year={2024}
}

@article{wen2023unveiling,
  title={Unveiling the implicit toxicity in large language models},
  author={Wen, Jiaxin and Ke, Pei and Sun, Hao and Zhang, Zhexin and Li, Chengfei and Bai, Jinfeng and Huang, Minlie},
  journal={arXiv preprint arXiv:2311.17391},
  year={2023}
}

@article{taubenfeld2024systematic,
  title={Systematic biases in LLM simulations of debates},
  author={Taubenfeld, Amir and Dover, Yaniv and Reichart, Roi and Goldstein, Ariel},
  journal={arXiv preprint arXiv:2402.04049},
  year={2024}
}

@inproceedings{yeh2023evaluating,
  title={Evaluating interfaced llm bias},
  author={Yeh, Kai-Ching and Chi, Jou-An and Lian, Da-Chen and Hsieh, Shu-Kai},
  booktitle={Proceedings of the 35th Conference on Computational Linguistics and Speech Processing (ROCLING 2023)},
  pages={292--299},
  year={2023}
}

@techreport{von2023assessing,
  title={Assessing Bias in LLM-Generated Synthetic Datasets: The Case of German Voter Behavior},
  author={von der Heyde, Leah and Haensch, Anna-Carolina and Wenz, Alexander},
  year={2023},
  institution={Center for Open Science}
}

@inproceedings{badyal2023intentional,
  title={Intentional Biases in LLM Responses},
  author={Badyal, Nicklaus and Jacoby, Derek and Coady, Yvonne},
  booktitle={2023 IEEE 14th Annual Ubiquitous Computing, Electronics \& Mobile Communication Conference (UEMCON)},
  pages={0502--0506},
  year={2023},
  organization={IEEE}
}

@article{li2021self,
  title={Self--other moral bias: Evidence from implicit measures and the Word-Embedding Association Test},
  author={Li, Ming-Hui and Li, Pei-Wei and Rao, Li-Lin},
  journal={Personality and Individual Differences},
  volume={183},
  pages={111107},
  year={2021},
  publisher={Elsevier}
}

@article{prior2008word,
  title={Word associations are formed incidentally during sentential semantic integration},
  author={Prior, Anat and Bentin, Shlomo},
  journal={Acta Psychologica},
  volume={127},
  number={1},
  pages={57--71},
  year={2008},
  publisher={Elsevier}
}

@InProceedings{rudinger-EtAl:2018:N18,
  author    = {Rudinger, Rachel  and  Naradowsky, Jason  and  Leonard, Brian  and  {Van Durme}, Benjamin},
  title     = {Gender Bias in Coreference Resolution},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2018},
  address   = {New Orleans, Louisiana},
  publisher = {Association for Computational Linguistics}
}

@misc{nadeem2020stereoset,
    title={StereoSet: Measuring stereotypical bias in pretrained language models},
    author={Moin Nadeem and Anna Bethke and Siva Reddy},
    year={2020},
    eprint={2004.09456},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{pessach2022review,
  title={A review on fairness in machine learning},
  author={Pessach, Dana and Shmueli, Erez},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={3},
  pages={1--44},
  year={2022},
  publisher={ACM New York, NY}
}

@article{yang2024matplotagent,
  title={MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization},
  author={Yang, Zhiyu and Zhou, Zihan and Wang, Shuo and Cong, Xin and Han, Xu and Yan, Yukun and Liu, Zhenghao and Tan, Zhixing and Liu, Pengyuan and Yu, Dong and others},
  journal={arXiv preprint arXiv:2402.11453},
  year={2024}
}

@inproceedings{chan2023harms,
  title={Harms from increasingly agentic algorithmic systems},
  author={Chan, Alan and Salganik, Rebecca and Markelius, Alva and Pang, Chris and Rajkumar, Nitarshan and Krasheninnikov, Dmitrii and Langosco, Lauro and He, Zhonghao and Duan, Yawen and Carroll, Micah and others},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={651--666},
  year={2023}
}

@article{fernandez2022fine,
  title={Fine-tuning BERT models for intent recognition using a frequency cut-off strategy for domain-specific vocabulary extension},
  author={Fern{\'a}ndez-Mart{\'\i}nez, Fernando and Luna-Jim{\'e}nez, Cristina and Kleinlein, Ricardo and Griol, David and Callejas, Zoraida and Montero, Juan Manuel},
  journal={Applied Sciences},
  volume={12},
  number={3},
  pages={1610},
  year={2022},
  publisher={MDPI}
}

@article{ngiam2018domain,
  title={Domain adaptive transfer learning with specialist models},
  author={Ngiam, Jiquan and Peng, Daiyi and Vasudevan, Vijay and Kornblith, Simon and Le, Quoc V and Pang, Ruoming},
  journal={arXiv preprint arXiv:1811.07056},
  year={2018}
}

@article{schimanski2024towards,
  title={Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering},
  author={Schimanski, Tobias and Ni, Jingwei and Kraus, Mathias and Ash, Elliott and Leippold, Markus},
  journal={arXiv preprint arXiv:2402.08277},
  year={2024}
}

@article{lecky1945self,
  title={Self-consistency; a theory of personality.},
  author={Lecky, Prescott},
  year={1945},
  publisher={Island Press}
}

@inproceedings{min2023beyond,
  title={Beyond Accuracy: Evaluating Self-Consistency of Code LLMs},
  author={Min, Marcus J and Ding, Yangruibo and Buratti, Luca and Pujar, Saurabh and Kaiser, Gail and Jana, Suman and Ray, Baishakhi},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{chen2023universal,
  title={Universal self-consistency for large language model generation},
  author={Chen, Xinyun and Aksitov, Renat and Alon, Uri and Ren, Jie and Xiao, Kefan and Yin, Pengcheng and Prakash, Sushant and Sutton, Charles and Wang, Xuezhi and Zhou, Denny},
  journal={arXiv preprint arXiv:2311.17311},
  year={2023}
}

@article{abu2024knowledge,
  title={Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations},
  author={Abu-Rasheed, Hasan and Weber, Christian and Fathi, Madjid},
  journal={arXiv preprint arXiv:2403.03008},
  year={2024}
}

@article{vamsi2024human,
  title={From human experts to machines: An LLM supported approach to ontology and knowledge graph construction},
  author={Vamsi, Krishna Kommineni and Kommineni, Vamsi Krishna and Samuel, Sheeba},
  year={2024}
}

@article{kang2024unfamiliar,
  title={Unfamiliar Finetuning Examples Control How Language Models Hallucinate},
  author={Kang, Katie and Wallace, Eric and Tomlin, Claire and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2403.05612},
  year={2024}
}

@article{shrestha2024fairrag,
  title={FairRAG: Fair Human Generation via Fair Retrieval Augmentation},
  author={Shrestha, Robik and Zou, Yang and Chen, Qiuyu and Li, Zhiheng and Xie, Yusheng and Deng, Siqi},
  journal={arXiv preprint arXiv:2403.19964},
  year={2024}
}

@article{van2021decaf,
  title={Decaf: Generating fair synthetic data using causally-aware generative networks},
  author={Van Breugel, Boris and Kyono, Trent and Berrevoets, Jeroen and Van der Schaar, Mihaela},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={22221--22233},
  year={2021}
}

@article{huang2024empirical,
  title={An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Models are Task-specific Classifiers},
  author={Huang, Hui and Qu, Yingqi and Liu, Jing and Yang, Muyun and Zhao, Tiejun},
  journal={arXiv preprint arXiv:2403.02839},
  year={2024}
}

@article{choi2022prompt,
  title={Prompt injection: Parameterization of fixed inputs},
  author={Choi, Eunbi and Jo, Yongrae and Jang, Joel and Seo, Minjoon},
  journal={arXiv preprint arXiv:2206.11349},
  year={2022}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@article{zheng2023helpful,
  title={Is" A Helpful Assistant" the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts},
  author={Zheng, Mingqian and Pei, Jiaxin and Jurgens, David},
  journal={arXiv preprint arXiv:2311.10054},
  year={2023}
}

@article{jeddi2020simple,
  title={A simple fine-tuning is all you need: Towards robust deep learning via adversarial fine-tuning},
  author={Jeddi, Ahmadreza and Shafiee, Mohammad Javad and Wong, Alexander},
  journal={arXiv preprint arXiv:2012.13628},
  year={2020}
}

@inproceedings{chen2020adversarial,
  title={Adversarial robustness: From self-supervised pre-training to fine-tuning},
  author={Chen, Tianlong and Liu, Sijia and Chang, Shiyu and Cheng, Yu and Amini, Lisa and Wang, Zhangyang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={699--708},
  year={2020}
}

@inproceedings{rahutomo2012semantic,
  title={Semantic cosine similarity},
  author={Rahutomo, Faisal and Kitasuka, Teruaki and Aritsugi, Masayoshi and others},
  booktitle={The 7th international student conference on advanced science and technology ICAST},
  volume={4},
  number={1},
  pages={1},
  year={2012},
  organization={University of Seoul South Korea}
}

@article{zhuang2024toolqa,
  title={Toolqa: A dataset for llm question answering with external tools},
  author={Zhuang, Yuchen and Yu, Yue and Wang, Kuan and Sun, Haotian and Zhang, Chao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{jha2023counterexample,
  title={Counterexample Guided Inductive Synthesis Using Large Language Models and Satisfiability Solving},
  author={Jha, Sumit Kumar and Jha, Susmit and Lincoln, Patrick and Bastian, Nathaniel D and Velasquez, Alvaro and Ewetz, Rickard and Neema, Sandeep},
  booktitle={MILCOM 2023-2023 IEEE Military Communications Conference (MILCOM)},
  pages={944--949},
  year={2023},
  organization={IEEE}
}

@inproceedings{rebedea-etal-2023-nemo,
    title = "{N}e{M}o Guardrails: A Toolkit for Controllable and Safe {LLM} Applications with Programmable Rails",
    author = "Rebedea, Traian  and
      Dinu, Razvan  and
      Sreedhar, Makesh Narsimhan  and
      Parisien, Christopher  and
      Cohen, Jonathan",
    editor = "Feng, Yansong  and
      Lefever, Els",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-demo.40",
    doi = "10.18653/v1/2023.emnlp-demo.40",
    pages = "431--445",
}

@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}